{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STACKS+BOWTIE+BLAST Pipeline for Population Genomics Analysis\n",
    "\n",
    "This is the full pipeline that I'm using to analyze my Pacific cod time series data, and I'm hoping to be able to use on future projects as well. Our lab uses the Stacks pipeline, followed by filtering our catalog with Bowtie and BLAST to filter down our catalog of loci into a de novo reference genome. \n",
    "\n",
    "One of my current concerns is that there are a couple of individual fish that Isadora sequenced twice, and I can't remember why, but I think she was testing some sort of method (like extraction, or shearing cycle number, etc.). The first time I ran through my pipeline I don't think I properly named the files, and I think I left one of them behind. So before I'm completely done with this data set (after FISH 546) I should go back and make sure I have things named right so I can show the data to Isadora.\n",
    "\n",
    "Here are the steps:\n",
    "\n",
    "### Steps\n",
    "\n",
    "#### 1. Add library identifier to file name (optional)\n",
    "\n",
    "#### 2. ``ustacks``\n",
    "\n",
    "#### 3.  ``cstacks``\n",
    "\n",
    "#### 4. ``sstacks``\n",
    "\n",
    "#### 5. ``populations``\n",
    "\n",
    "#### 6. Filter catalog with ``bowtie``\n",
    "\n",
    "#### 7. Filter catalog with ``BLAST``\n",
    "\n",
    "#### 8. Create final reference genome and align reads with ``bowtie``\n",
    "\n",
    "#### 9. ``pstacks``\n",
    "\n",
    "#### 10. ``sstacks``\n",
    "\n",
    "#### 11. ``populations``\n",
    "\n",
    "#### 12. Additional filtering with Marine's scripts\n",
    "\n",
    "#### 13. Statistial tests in R\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Go to working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/Volumes/Time Machine Backups/Cod-Time-Series-Data/'\n",
      "/Users/natalielowell/Git-repos/FISH546/Cod-Time-Series-Project/Notebooks\n"
     ]
    }
   ],
   "source": [
    "cd /Volumes/Time\\ Machine\\ Backups/Cod-Time-Series-Data/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Adding library identifier to file names\n",
    "\n",
    "If you are analyzing data run on multiple lanes, it may be useful to rename your files such that they have the unique library identifier (eg., \\_L1 or \\_L2) because barcodes will be redundant between libraries. I wrote a [script](https://github.com/nclowell/FISH546/blob/master/Cod-Time-Series-Project/Scripts/add_lib_to_filename.py) that will add this to your filenames.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!python add_lib_to_filename.py process_radtags_out/cod_lib1 _L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!python add_lib_to_filename.py process_radtags_out/cod_lib2 _L2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Running ``ustacks``\n",
    "\n",
    "``ustacks`` [documentation](http://catchenlab.life.illinois.edu/stacks/comp/ustacks.php) highlights:\n",
    "\n",
    "<br>ustacks -t file_type -f file_path [-d] [-r] [-o path] [-i id] [-m min_cov] [-M max_dist] [-p num_threads] [-R] [-H] [-h]\n",
    "<br>t — input file Type. Supported types: fasta, fastq, gzfasta, or gzfastq.\n",
    "<br>f — input file path.\n",
    "<br>o — output path to write results.\n",
    "<br>i — SQL ID to insert into the output to identify this sample.\n",
    "<br>m — Minimum depth of coverage required to create a stack (default 2).\n",
    "<br>M — Maximum distance (in nucleotides) allowed between stacks (default 2).\n",
    "<br>N — Maximum distance allowed to align secondary reads to primary stacks (default: M + 2).\n",
    "<br>R — retain unused reads.\n",
    "<br>H — disable calling haplotypes from secondary reads.\n",
    "<br>p — enable parallel execution with num_threads threads.\n",
    "<br>h — display this help messsage.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "Running custom python [script for ``ustacks``](https://github.com/nclowell/FISH546/blob/master/Cod-Time-Series-Project/Scripts/pypipe_ustacks.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!python pypipe_ustacks.py barcodes_samplenames.txt ./process_radtags_out ./ustacks_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Running ``cstacks``\n",
    "``cstacks`` [documentation](http://catchenlab.life.illinois.edu/stacks/comp/cstacks.php) highlights:\n",
    "\n",
    "<br>cstacks -b batch_id -s sample_file [-s sample_file_2 ...] [-o path] [-n num] [-g] [-p num_threads] [--catalog path] [-h]\n",
    "<br>p — enable parallel execution with num_threads threads.\n",
    "<br>b — MySQL ID of this batch.\n",
    "<br>s — TSV file from which to load radtags.\n",
    "<br>o — output path to write results.\n",
    "<br>m — include tags in the catalog that match to more than one entry.\n",
    "<br>n — number of mismatches allowed between sample tags when generating the catalog.\n",
    "<br>g — base catalog matching on genomic location, not sequence identity.\n",
    "<br>h — display this help messsage.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "Running custom python [script for ``cstacks``](https://github.com/nclowell/FISH546/blob/master/Cod-Time-Series-Project/Scripts/pypipe_cstacks.py):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/Time Machine Backups/Cod-Time-Series-Data\n"
     ]
    }
   ],
   "source": [
    "cd /Volumes/Time\\ Machine\\ Backups/Cod-Time-Series-Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cstacks paramters selected:\n",
      "  Loci matched based on sequence identity.\n",
      "  Number of mismatches allowed between stacks: 3\n",
      "  Gapped alignments: disabled\n",
      "Constructing catalog from 10 samples.\n",
      "Initializing new catalog...\n",
      " Unable to open 'process_radtags_out/2015_101_1'\n",
      "Failed to initialize the catalog.\n"
     ]
    }
   ],
   "source": [
    "!python pypipe_cstacks.py prt_out_filenames.txt ../process_radtags_out 10 3 stacks_out_b3 3 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Running ``sstacks``\n",
    "``sstacks`` [documentation](http://catchenlab.life.illinois.edu/stacks/comp/sstacks.php) highlights:\n",
    "\n",
    "<br>sstacks -b batch_id -c catalog_file -s sample_file [-s sample_file_2 ...] [-o path] [-p num_threads] [-g] [-x] [-v] [-h]\n",
    "<br>p — enable parallel execution with num_threads threads.\n",
    "<br>b — MySQL ID of this batch.\n",
    "<br>c — TSV file from which to load the catalog loci.\n",
    "<br>s — TSV file from which to load sample loci.\n",
    "<br>o — output path to write results.\n",
    "<br>g — base matching on genomic location, not sequence identity.\n",
    "<br>x — don’t verify haplotype of matching locus.\n",
    "<br>v — print program version.\n",
    "<br>h — display this help messsage.\n",
    "\n",
    "Running custom python [script for ``sstacks``](https://github.com/nclowell/FISH546/blob/master/Cod-Time-Series-Project/Scripts/pypipe_sstacks.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!python pypipe_sstacks.py new_filenames_shell.txt 2 ustacks_out/batch_1 ustacks_out 10 -o sstacks_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Running ``populations``\n",
    "\n",
    "Documentation [here](http://catchenlab.life.illinois.edu/stacks/comp/populations.php).\n",
    "\n",
    "Example code:\n",
    "```\n",
    "!populations -b 2 -P ustacks_out -M popmap1.txt -t 10 -r 0.50 -p 2 -m 5 --genepop\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "populations -b 2 -P ustacks_out -M popmap1.txt -t 10 -r 0.50 -p 1 -m 10 --genepop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Filter with ``Bowtie``\n",
    "\n",
    "<br>\n",
    "First, make a fasta file for ``Bowtie`` from the tags file. You will need to be in the directory of your ``cstacks`` output. This involves running a custom python [script](https://github.com/nclowell/FISH546/blob/master/Cod-Time-Series-Project/Scripts/genBOWTIEfasta.py) that Marine wrote, and requires the catalog tags file and the name of the loci, which I can get from the header of another catalog file and copying and pasting into a new text file, where each value is locusnumber_snpnumber, and everything is comma separated.\n",
    "\n",
    "[Documentation](http://bowtie-bio.sourceforge.net/manual.shtml) highlights:\n",
    "\n",
    "<br>bowtie-build [options]\n",
    "<br>Main arguments\n",
    "\n",
    "##### reference_in\n",
    "A comma-separated list of FASTA files containing the reference sequences to be aligned to, or, if -c is specified, the sequences themselves. E.g., <reference_in> might be chr1.fa,chr2.fa,chrX.fa,chrY.fa, or, if -c is specified, this might be <br>GGTCATCCT,ACGGGTCGT,CCGTTCTATGCGGCTTA.\n",
    "\n",
    "##### -f\n",
    "The reference input files (specified as (reference_in)) are FASTA files (usually having extension .fa, .mfa, .fna or similar).\n",
    "\n",
    "##### ebwt_base\n",
    "The basename of the index files to write. By default, bowtie-build writes files named <br>NAME.1.ebwt, NAME.2.ebwt, NAME.3.ebwt, NAME.4.ebwt, NAME.rev.1.ebwt, and NAME.rev.2.ebwt, <br>where NAME is <ebwt_base>.\n",
    "\n",
    "<br>bowtie [options]\n",
    "<br>Main arguments\n",
    "\n",
    "##### -v (integer)\n",
    "Report alignments with at most (integer) mismatches. -e and -l options are ignored and quality values have no effect on what alignments are valid. -v is mutually exclusive with -n.\n",
    "\n",
    "\n",
    "##### -S/--sam\n",
    "Print alignments in SAM format. See the SAM output section of the manual for details. To suppress all SAM headers, use --sam-nohead in addition to -S/--sam.\n",
    "\n",
    "<br>\n",
    "Here, I made batch_2_loci.txt for this round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/Time Machine Backups/Cod-Time-Series-Data/ustacks_out\n"
     ]
    }
   ],
   "source": [
    "cd /Volumes/Time\\ Machine\\ Backups/Cod-Time-Series-Data/ustacks_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!gzip -d batch_2.catalog.tags.tsv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/Time Machine Backups/Cod-Time-Series-Data/scripts\n"
     ]
    }
   ],
   "source": [
    "cd ../scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!python genBOWTIEfasta.py ../ustacks_out/batch_2_loci.txt ../ustacks_out/batch_2.catalog.tags.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Make a directory for ``Bowtie`` files and navigate there. Store the software there. Then use ``Bowtie`` to make a reference genome. Also, genBOWTIEfasta.py stores the new file in the same folder you're running the script fromm, so it may be worth editing the script at some point to direct where it saves. For now, I'll continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/Time Machine Backups/Cod-Time-Series-Data\n"
     ]
    }
   ],
   "source": [
    "cd /Volumes/Time\\ Machine\\ Backups/Cod-Time-Series-Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir Bowtie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/Time Machine Backups/Cod-Time-Series-Data/Bowtie/bowtie-1.1.2\n"
     ]
    }
   ],
   "source": [
    "cd /Volumes/Time Machine Backups/Cod-Time-Series-Data/Bowtie/bowtie-1.1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the Bowtie index, which produces some files that are all you need to align to the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings:\n",
      "  Output files: \"batch_2.*.ebwt\"\n",
      "  Line rate: 6 (line is 64 bytes)\n",
      "  Lines per side: 1 (side is 64 bytes)\n",
      "  Offset rate: 5 (one in 32)\n",
      "  FTable chars: 10\n",
      "  Strings: unpacked\n",
      "  Max bucket size: default\n",
      "  Max bucket size, sqrt multiplier: default\n",
      "  Max bucket size, len divisor: 4\n",
      "  Difference-cover sample period: 1024\n",
      "  Endianness: little\n",
      "  Actual local endianness: little\n",
      "  Sanity checking: disabled\n",
      "  Assertions: disabled\n",
      "  Random seed: 0\n",
      "  Sizeofs: void*:8, int:4, long:8, size_t:8\n",
      "Input files DNA, FASTA:\n",
      "  seqsforBOWTIE.fa\n",
      "Reading reference sizes\n",
      "  Time reading reference sizes: 00:00:00\n",
      "Calculating joined length\n",
      "Writing header\n",
      "Reserving space for joined string\n",
      "Joining reference sequences\n",
      "  Time to join reference sequences: 00:00:00\n",
      "bmax according to bmaxDivN setting: 219600\n",
      "Using parameters --bmax 164700 --dcv 1024\n",
      "  Doing ahead-of-time memory usage test\n",
      "  Passed!  Constructing with these parameters: --bmax 164700 --dcv 1024\n",
      "Constructing suffix-array element generator\n",
      "Building DifferenceCoverSample\n",
      "  Building sPrime\n",
      "  Building sPrimeOrder\n",
      "  V-Sorting samples\n",
      "  V-Sorting samples time: 00:00:00\n",
      "  Allocating rank array\n",
      "  Ranking v-sort output\n",
      "  Ranking v-sort output time: 00:00:00\n",
      "  Invoking Larsson-Sadakane on ranks\n",
      "  Invoking Larsson-Sadakane on ranks time: 00:00:00\n",
      "  Sanity-checking and returning\n",
      "Building samples\n",
      "Reserving space for 12 sample suffixes\n",
      "Generating random suffixes\n",
      "QSorting 12 sample offsets, eliminating duplicates\n",
      "QSorting sample offsets, eliminating duplicates time: 00:00:00\n",
      "Multikey QSorting 12 samples\n",
      "  (Using difference cover)\n",
      "  Multikey QSorting samples time: 00:00:00\n",
      "Calculating bucket sizes\n",
      "  Binary sorting into buckets\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Binary sorting into buckets time: 00:00:00\n",
      "Splitting and merging\n",
      "  Splitting and merging time: 00:00:00\n",
      "Split 1, merged 6; iterating...\n",
      "  Binary sorting into buckets\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Binary sorting into buckets time: 00:00:00\n",
      "Splitting and merging\n",
      "  Splitting and merging time: 00:00:00\n",
      "Split 1, merged 1; iterating...\n",
      "  Binary sorting into buckets\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Binary sorting into buckets time: 00:00:00\n",
      "Splitting and merging\n",
      "  Splitting and merging time: 00:00:00\n",
      "Avg bucket size: 109799 (target: 164699)\n",
      "Converting suffix-array elements to index image\n",
      "Allocating ftab, absorbFtab\n",
      "Entering Ebwt loop\n",
      "Getting block 1 of 8\n",
      "  Reserving size (164700) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 119091\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 119092\n",
      "Getting block 2 of 8\n",
      "  Reserving size (164700) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 158536\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 158537\n",
      "Getting block 3 of 8\n",
      "  Reserving size (164700) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 89945\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 89946\n",
      "Getting block 4 of 8\n",
      "  Reserving size (164700) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 136720\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:01\n",
      "Returning block of 136721\n",
      "Getting block 5 of 8\n",
      "  Reserving size (164700) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 123481\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 123482\n",
      "Getting block 6 of 8\n",
      "  Reserving size (164700) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 81541\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 81542\n",
      "Getting block 7 of 8\n",
      "  Reserving size (164700) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 142837\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 142838\n",
      "Getting block 8 of 8\n",
      "  Reserving size (164700) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 26242\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 26243\n",
      "Exited Ebwt loop\n",
      "fchr[A]: 0\n",
      "fchr[C]: 217879\n",
      "fchr[G]: 438121\n",
      "fchr[T]: 674641\n",
      "fchr[$]: 878400\n",
      "Exiting Ebwt::buildToDisk()\n",
      "Returning from initFromVector\n",
      "Wrote 4577594 bytes to primary EBWT file: batch_2.1.ebwt\n",
      "Wrote 109808 bytes to secondary EBWT file: batch_2.2.ebwt\n",
      "Re-opening _in1 and _in2 as input streams\n",
      "Returning from Ebwt constructor\n",
      "Headers:\n",
      "    len: 878400\n",
      "    bwtLen: 878401\n",
      "    sz: 219600\n",
      "    bwtSz: 219601\n",
      "    lineRate: 6\n",
      "    linesPerSide: 1\n",
      "    offRate: 5\n",
      "    offMask: 0xffffffe0\n",
      "    isaRate: -1\n",
      "    isaMask: 0xffffffff\n",
      "    ftabChars: 10\n",
      "    eftabLen: 20\n",
      "    eftabSz: 80\n",
      "    ftabLen: 1048577\n",
      "    ftabSz: 4194308\n",
      "    offsLen: 27451\n",
      "    offsSz: 109804\n",
      "    isaLen: 0\n",
      "    isaSz: 0\n",
      "    lineSz: 64\n",
      "    sideSz: 64\n",
      "    sideBwtSz: 56\n",
      "    sideBwtLen: 224\n",
      "    numSidePairs: 1961\n",
      "    numSides: 3922\n",
      "    numLines: 3922\n",
      "    ebwtTotLen: 251008\n",
      "    ebwtTotSz: 251008\n",
      "    reverse: 0\n",
      "Total time for call to driver() for forward index: 00:00:01\n",
      "Reading reference sizes\n",
      "  Time reading reference sizes: 00:00:00\n",
      "Calculating joined length\n",
      "Writing header\n",
      "Reserving space for joined string\n",
      "Joining reference sequences\n",
      "  Time to join reference sequences: 00:00:00\n",
      "bmax according to bmaxDivN setting: 219600\n",
      "Using parameters --bmax 164700 --dcv 1024\n",
      "  Doing ahead-of-time memory usage test\n",
      "  Passed!  Constructing with these parameters: --bmax 164700 --dcv 1024\n",
      "Constructing suffix-array element generator\n",
      "Building DifferenceCoverSample\n",
      "  Building sPrime\n",
      "  Building sPrimeOrder\n",
      "  V-Sorting samples\n",
      "  V-Sorting samples time: 00:00:00\n",
      "  Allocating rank array\n",
      "  Ranking v-sort output\n",
      "  Ranking v-sort output time: 00:00:00\n",
      "  Invoking Larsson-Sadakane on ranks\n",
      "  Invoking Larsson-Sadakane on ranks time: 00:00:00\n",
      "  Sanity-checking and returning\n",
      "Building samples\n",
      "Reserving space for 12 sample suffixes\n",
      "Generating random suffixes\n",
      "QSorting 12 sample offsets, eliminating duplicates\n",
      "QSorting sample offsets, eliminating duplicates time: 00:00:00\n",
      "Multikey QSorting 12 samples\n",
      "  (Using difference cover)\n",
      "  Multikey QSorting samples time: 00:00:00\n",
      "Calculating bucket sizes\n",
      "  Binary sorting into buckets\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Binary sorting into buckets time: 00:00:00\n",
      "Splitting and merging\n",
      "  Splitting and merging time: 00:00:00\n",
      "Split 2, merged 7; iterating...\n",
      "  Binary sorting into buckets\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Binary sorting into buckets time: 00:00:00\n",
      "Splitting and merging\n",
      "  Splitting and merging time: 00:00:00\n",
      "Split 2, merged 1; iterating...\n",
      "  Binary sorting into buckets\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Binary sorting into buckets time: 00:00:00\n",
      "Splitting and merging\n",
      "  Splitting and merging time: 00:00:00\n",
      "Split 2, merged 1; iterating...\n",
      "  Binary sorting into buckets\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Binary sorting into buckets time: 00:00:00\n",
      "Splitting and merging\n",
      "  Splitting and merging time: 00:00:00\n",
      "Avg bucket size: 125485 (target: 164699)\n",
      "Converting suffix-array elements to index image\n",
      "Allocating ftab, absorbFtab\n",
      "Entering Ebwt loop\n",
      "Getting block 1 of 7\n",
      "  Reserving size (164700) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 39651\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 39652\n",
      "Getting block 2 of 7\n",
      "  Reserving size (164700) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 150749\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 150750\n",
      "Getting block 3 of 7\n",
      "  Reserving size (164700) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 86028\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 86029\n",
      "Getting block 4 of 7\n",
      "  Reserving size (164700) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 161469\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 161470\n",
      "Getting block 5 of 7\n",
      "  Reserving size (164700) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 163835\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 163836\n",
      "Getting block 6 of 7\n",
      "  Reserving size (164700) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 160470\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 160471\n",
      "Getting block 7 of 7\n",
      "  Reserving size (164700) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 116192\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 116193\n",
      "Exited Ebwt loop\n",
      "fchr[A]: 0\n",
      "fchr[C]: 217879\n",
      "fchr[G]: 438121\n",
      "fchr[T]: 674641\n",
      "fchr[$]: 878400\n",
      "Exiting Ebwt::buildToDisk()\n",
      "Returning from initFromVector\n",
      "Wrote 4577594 bytes to primary EBWT file: batch_2.rev.1.ebwt\n",
      "Wrote 109808 bytes to secondary EBWT file: batch_2.rev.2.ebwt\n",
      "Re-opening _in1 and _in2 as input streams\n",
      "Returning from Ebwt constructor\n",
      "Headers:\n",
      "    len: 878400\n",
      "    bwtLen: 878401\n",
      "    sz: 219600\n",
      "    bwtSz: 219601\n",
      "    lineRate: 6\n",
      "    linesPerSide: 1\n",
      "    offRate: 5\n",
      "    offMask: 0xffffffe0\n",
      "    isaRate: -1\n",
      "    isaMask: 0xffffffff\n",
      "    ftabChars: 10\n",
      "    eftabLen: 20\n",
      "    eftabSz: 80\n",
      "    ftabLen: 1048577\n",
      "    ftabSz: 4194308\n",
      "    offsLen: 27451\n",
      "    offsSz: 109804\n",
      "    isaLen: 0\n",
      "    isaSz: 0\n",
      "    lineSz: 64\n",
      "    sideSz: 64\n",
      "    sideBwtSz: 56\n",
      "    sideBwtLen: 224\n",
      "    numSidePairs: 1961\n",
      "    numSides: 3922\n",
      "    numLines: 3922\n",
      "    ebwtTotLen: 251008\n",
      "    ebwtTotSz: 251008\n",
      "    reverse: 0\n",
      "Total time for backward call to driver() for mirror index: 00:00:00\n"
     ]
    }
   ],
   "source": [
    "!./bowtie-build seqsforBOWTIE.fa batch_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, align it to itself and filter out any sequences that aligned to sequences other than themselves using a custom [script](https://github.com/nclowell/FISH546/blob/master/Cod-Time-Series-Project/Scripts/parseBowtie_DD.py) that Dan wrote in our lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# reads processed: 6100\r\n",
      "# reads with at least one reported alignment: 6100 (100.00%)\r\n",
      "# reads that failed to align: 0 (0.00%)\r\n",
      "Reported 6100 alignments to 1 output stream(s)\r\n"
     ]
    }
   ],
   "source": [
    "!./bowtie -f -v 3 --sam --sam-nohead \\\n",
    "batch_2 \\\n",
    "seqsforBOWTIE.fa \\\n",
    "batch_2_BOWTIEout.sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/Time Machine Backups/Cod-Time-Series-Data/scripts\n"
     ]
    }
   ],
   "source": [
    "cd ../../scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Bowtie output lines read: 6100\n",
      "Number of sequences written to output: 6100\n"
     ]
    }
   ],
   "source": [
    "!python parseBowtie_DD.py ../Bowtie/bowtie-1.1.2/batch_2_BOWTIEout.sam ../Bowtie/bowtie-1.1.2/batch_2_BOWTIEout_filtered.fa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Filter with ``BLAST``\n",
    "\n",
    "<br>\n",
    "Change directory to highest project directory, here Cod Time Series Data. Then, make a directory for Blast and make a Blast database out of the output from Bowtie. This requires me to move the filtered fasta file, which I did manually. \n",
    "\n",
    "Then, we'll be filtering out any loci that match other loci equally well or better than to themselves, which is supposed to remove highly repetitive loci like microsatellites that can interfere with our data analysis. This [script](https://github.com/nclowell/FISH546/blob/master/Cod-Time-Series-Project/Scripts/checkBlastResults_DD.py) for Blast filtering was also written by Dan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/Time Machine Backups/Cod-Time-Series-Data\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mkdir Blast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/Time Machine Backups/Cod-Time-Series-Data/Blast\n"
     ]
    }
   ],
   "source": [
    "cd Blast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 12/05/2016 11:39:24\n",
      "New DB name:   /Volumes/Time Machine Backups/Cod-Time-Series-Data/Blast/batch_2_BOWTIEfiltered\n",
      "New DB title:  batch_2_BOWTIEout_filtered.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 6100 sequences in 0.619313 seconds.\n"
     ]
    }
   ],
   "source": [
    "!makeblastdb -in batch_2_BOWTIEout_filtered.fa \\\n",
    "-parse_seqids \\\n",
    "-dbtype nucl \\\n",
    "-out batch_2_BOWTIEfiltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!blastn -query batch_2_BOWTIEout_filtered.fa \\\n",
    "-db batch_2_BOWTIEfiltered \\\n",
    "-out batch_2_BowtieBlastFiltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/Time Machine Backups/Cod-Time-Series-Data/scripts\n"
     ]
    }
   ],
   "source": [
    "cd ../scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Identifying which loci are 'good' and 'bad' based on BLAST alignments...\n",
      "Writing 'good' and 'bad' loci to their respective files...\n"
     ]
    }
   ],
   "source": [
    "!python checkBlastResults_DD.py \\\n",
    "../Blast/batch_2_BowtieBlastFiltered \\\n",
    "../Blast/batch_2_BOWTIEout_filtered.fa \\\n",
    "../Blast/batch_2_BowtieBlastFiltered_GOOD.fa \\\n",
    "../Blast/batch_2_BowtieBlastFiltered_BAD.fa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now to check how many loci were retained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/Time Machine Backups/Cod-Time-Series-Data/Blast\n"
     ]
    }
   ],
   "source": [
    "cd ../Blast/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    5949\r\n"
     ]
    }
   ],
   "source": [
    "!grep \">\" batch_2_BowtieBlastFiltered_GOOD.fa | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     151\r\n"
     ]
    }
   ],
   "source": [
    "!grep \">\" batch_2_BowtieBlastFiltered_BAD.fa | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 8. Create final reference genome with ``bowtie``\n",
    "\n",
    "Lastly, I need to use Bowtie again to build a final Bowtie index using the files cleaned in Blast, and then use Bowtie to align all of my fastq files to the Bowtie index for ``pstacks``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/Time Machine Backups/Cod-Time-Series-Data/Bowtie/bowtie-1.1.2\n"
     ]
    }
   ],
   "source": [
    "cd /Volumes/Time Machine Backups/Cod-Time-Series-Data/Bowtie/bowtie-1.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings:\n",
      "  Output files: \"batch_2_df.*.ebwt\"\n",
      "  Line rate: 6 (line is 64 bytes)\n",
      "  Lines per side: 1 (side is 64 bytes)\n",
      "  Offset rate: 5 (one in 32)\n",
      "  FTable chars: 10\n",
      "  Strings: unpacked\n",
      "  Max bucket size: default\n",
      "  Max bucket size, sqrt multiplier: default\n",
      "  Max bucket size, len divisor: 4\n",
      "  Difference-cover sample period: 1024\n",
      "  Endianness: little\n",
      "  Actual local endianness: little\n",
      "  Sanity checking: disabled\n",
      "  Assertions: disabled\n",
      "  Random seed: 0\n",
      "  Sizeofs: void*:8, int:4, long:8, size_t:8\n",
      "Input files DNA, FASTA:\n",
      "  batch_2_BowtieBlastFiltered_GOOD.fa\n",
      "Reading reference sizes\n",
      "  Time reading reference sizes: 00:00:00\n",
      "Calculating joined length\n",
      "Writing header\n",
      "Reserving space for joined string\n",
      "Joining reference sequences\n",
      "  Time to join reference sequences: 00:00:00\n",
      "bmax according to bmaxDivN setting: 214164\n",
      "Using parameters --bmax 160623 --dcv 1024\n",
      "  Doing ahead-of-time memory usage test\n",
      "  Passed!  Constructing with these parameters: --bmax 160623 --dcv 1024\n",
      "Constructing suffix-array element generator\n",
      "Building DifferenceCoverSample\n",
      "  Building sPrime\n",
      "  Building sPrimeOrder\n",
      "  V-Sorting samples\n",
      "  V-Sorting samples time: 00:00:00\n",
      "  Allocating rank array\n",
      "  Ranking v-sort output\n",
      "  Ranking v-sort output time: 00:00:00\n",
      "  Invoking Larsson-Sadakane on ranks\n",
      "  Invoking Larsson-Sadakane on ranks time: 00:00:00\n",
      "  Sanity-checking and returning\n",
      "Building samples\n",
      "Reserving space for 12 sample suffixes\n",
      "Generating random suffixes\n",
      "QSorting 12 sample offsets, eliminating duplicates\n",
      "QSorting sample offsets, eliminating duplicates time: 00:00:00\n",
      "Multikey QSorting 12 samples\n",
      "  (Using difference cover)\n",
      "  Multikey QSorting samples time: 00:00:00\n",
      "Calculating bucket sizes\n",
      "  Binary sorting into buckets\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Binary sorting into buckets time: 00:00:00\n",
      "Splitting and merging\n",
      "  Splitting and merging time: 00:00:00\n",
      "Split 1, merged 6; iterating...\n",
      "  Binary sorting into buckets\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Binary sorting into buckets time: 00:00:00\n",
      "Splitting and merging\n",
      "  Splitting and merging time: 00:00:00\n",
      "Split 1, merged 0; iterating...\n",
      "  Binary sorting into buckets\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Binary sorting into buckets time: 00:00:00\n",
      "Splitting and merging\n",
      "  Splitting and merging time: 00:00:00\n",
      "Avg bucket size: 122379 (target: 160622)\n",
      "Converting suffix-array elements to index image\n",
      "Allocating ftab, absorbFtab\n",
      "Entering Ebwt loop\n",
      "Getting block 1 of 7\n",
      "  Reserving size (160623) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 127855\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 127856\n",
      "Getting block 2 of 7\n",
      "  Reserving size (160623) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 137683\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 137684\n",
      "Getting block 3 of 7\n",
      "  Reserving size (160623) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 95793\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 95794\n",
      "Getting block 4 of 7\n",
      "  Reserving size (160623) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 138307\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 138308\n",
      "Getting block 5 of 7\n",
      "  Reserving size (160623) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 124260\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 124261\n",
      "Getting block 6 of 7\n",
      "  Reserving size (160623) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 102303\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 102304\n",
      "Getting block 7 of 7\n",
      "  Reserving size (160623) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 130449\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 130450\n",
      "Exited Ebwt loop\n",
      "fchr[A]: 0\n",
      "fchr[C]: 211453\n",
      "fchr[G]: 426601\n",
      "fchr[T]: 656322\n",
      "fchr[$]: 856656\n",
      "Exiting Ebwt::buildToDisk()\n",
      "Returning from initFromVector\n",
      "Wrote 4568180 bytes to primary EBWT file: batch_2_df.1.ebwt\n",
      "Wrote 107088 bytes to secondary EBWT file: batch_2_df.2.ebwt\n",
      "Re-opening _in1 and _in2 as input streams\n",
      "Returning from Ebwt constructor\n",
      "Headers:\n",
      "    len: 856656\n",
      "    bwtLen: 856657\n",
      "    sz: 214164\n",
      "    bwtSz: 214165\n",
      "    lineRate: 6\n",
      "    linesPerSide: 1\n",
      "    offRate: 5\n",
      "    offMask: 0xffffffe0\n",
      "    isaRate: -1\n",
      "    isaMask: 0xffffffff\n",
      "    ftabChars: 10\n",
      "    eftabLen: 20\n",
      "    eftabSz: 80\n",
      "    ftabLen: 1048577\n",
      "    ftabSz: 4194308\n",
      "    offsLen: 26771\n",
      "    offsSz: 107084\n",
      "    isaLen: 0\n",
      "    isaSz: 0\n",
      "    lineSz: 64\n",
      "    sideSz: 64\n",
      "    sideBwtSz: 56\n",
      "    sideBwtLen: 224\n",
      "    numSidePairs: 1913\n",
      "    numSides: 3826\n",
      "    numLines: 3826\n",
      "    ebwtTotLen: 244864\n",
      "    ebwtTotSz: 244864\n",
      "    reverse: 0\n",
      "Total time for call to driver() for forward index: 00:00:00\n",
      "Reading reference sizes\n",
      "  Time reading reference sizes: 00:00:00\n",
      "Calculating joined length\n",
      "Writing header\n",
      "Reserving space for joined string\n",
      "Joining reference sequences\n",
      "  Time to join reference sequences: 00:00:00\n",
      "bmax according to bmaxDivN setting: 214164\n",
      "Using parameters --bmax 160623 --dcv 1024\n",
      "  Doing ahead-of-time memory usage test\n",
      "  Passed!  Constructing with these parameters: --bmax 160623 --dcv 1024\n",
      "Constructing suffix-array element generator\n",
      "Building DifferenceCoverSample\n",
      "  Building sPrime\n",
      "  Building sPrimeOrder\n",
      "  V-Sorting samples\n",
      "  V-Sorting samples time: 00:00:00\n",
      "  Allocating rank array\n",
      "  Ranking v-sort output\n",
      "  Ranking v-sort output time: 00:00:00\n",
      "  Invoking Larsson-Sadakane on ranks\n",
      "  Invoking Larsson-Sadakane on ranks time: 00:00:00\n",
      "  Sanity-checking and returning\n",
      "Building samples\n",
      "Reserving space for 12 sample suffixes\n",
      "Generating random suffixes\n",
      "QSorting 12 sample offsets, eliminating duplicates\n",
      "QSorting sample offsets, eliminating duplicates time: 00:00:00\n",
      "Multikey QSorting 12 samples\n",
      "  (Using difference cover)\n",
      "  Multikey QSorting samples time: 00:00:00\n",
      "Calculating bucket sizes\n",
      "  Binary sorting into buckets\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Binary sorting into buckets time: 00:00:00\n",
      "Splitting and merging\n",
      "  Splitting and merging time: 00:00:00\n",
      "Split 2, merged 6; iterating...\n",
      "  Binary sorting into buckets\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Binary sorting into buckets time: 00:00:00\n",
      "Splitting and merging\n",
      "  Splitting and merging time: 00:00:00\n",
      "Avg bucket size: 107081 (target: 160622)\n",
      "Converting suffix-array elements to index image\n",
      "Allocating ftab, absorbFtab\n",
      "Entering Ebwt loop\n",
      "Getting block 1 of 8\n",
      "  Reserving size (160623) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 122672\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 122673\n",
      "Getting block 2 of 8\n",
      "  Reserving size (160623) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 134113\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 134114\n",
      "Getting block 3 of 8\n",
      "  Reserving size (160623) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 114064\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 114065\n",
      "Getting block 4 of 8\n",
      "  Reserving size (160623) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 124115\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 124116\n",
      "Getting block 5 of 8\n",
      "  Reserving size (160623) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 58934\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 58935\n",
      "Getting block 6 of 8\n",
      "  Reserving size (160623) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 123912\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 123913\n",
      "Getting block 7 of 8\n",
      "  Reserving size (160623) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 117929\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 117930\n",
      "Getting block 8 of 8\n",
      "  Reserving size (160623) for bucket\n",
      "  Calculating Z arrays\n",
      "  Calculating Z arrays time: 00:00:00\n",
      "  Entering block accumulator loop:\n",
      "  10%\n",
      "  20%\n",
      "  30%\n",
      "  40%\n",
      "  50%\n",
      "  60%\n",
      "  70%\n",
      "  80%\n",
      "  90%\n",
      "  100%\n",
      "  Block accumulator loop time: 00:00:00\n",
      "  Sorting block of length 60910\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 60911\n",
      "Exited Ebwt loop\n",
      "fchr[A]: 0\n",
      "fchr[C]: 211453\n",
      "fchr[G]: 426601\n",
      "fchr[T]: 656322\n",
      "fchr[$]: 856656\n",
      "Exiting Ebwt::buildToDisk()\n",
      "Returning from initFromVector\n",
      "Wrote 4568180 bytes to primary EBWT file: batch_2_df.rev.1.ebwt\n",
      "Wrote 107088 bytes to secondary EBWT file: batch_2_df.rev.2.ebwt\n",
      "Re-opening _in1 and _in2 as input streams\n",
      "Returning from Ebwt constructor\n",
      "Headers:\n",
      "    len: 856656\n",
      "    bwtLen: 856657\n",
      "    sz: 214164\n",
      "    bwtSz: 214165\n",
      "    lineRate: 6\n",
      "    linesPerSide: 1\n",
      "    offRate: 5\n",
      "    offMask: 0xffffffe0\n",
      "    isaRate: -1\n",
      "    isaMask: 0xffffffff\n",
      "    ftabChars: 10\n",
      "    eftabLen: 20\n",
      "    eftabSz: 80\n",
      "    ftabLen: 1048577\n",
      "    ftabSz: 4194308\n",
      "    offsLen: 26771\n",
      "    offsSz: 107084\n",
      "    isaLen: 0\n",
      "    isaSz: 0\n",
      "    lineSz: 64\n",
      "    sideSz: 64\n",
      "    sideBwtSz: 56\n",
      "    sideBwtLen: 224\n",
      "    numSidePairs: 1913\n",
      "    numSides: 3826\n",
      "    numLines: 3826\n",
      "    ebwtTotLen: 244864\n",
      "    ebwtTotSz: 244864\n",
      "    reverse: 0\n",
      "Total time for backward call to driver() for mirror index: 00:00:01\n"
     ]
    }
   ],
   "source": [
    "!./bowtie-build batch_2_BowtieBlastFiltered_GOOD.fa batch_2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are working with 102 files. Consider checking your code if you expected a different number of files.\n",
      "^CTraceback (most recent call last):\n",
      "  File \"final_bowtie_shell.py\", line 51, in <module>\n",
      "    subprocess.call([\"sh final_bowtie_shell.txt\"], shell = True) # run shell script\n",
      "  File \"//anaconda/lib/python2.7/subprocess.py\", line 523, in call\n",
      "    return Popen(*popenargs, **kwargs).wait()\n",
      "  File \"//anaconda/lib/python2.7/subprocess.py\", line 1392, in wait\n",
      "    pid, sts = _eintr_retry_call(os.waitpid, self.pid, 0)\n",
      "  File \"//anaconda/lib/python2.7/subprocess.py\", line 476, in _eintr_retry_call\n",
      "    return func(*args)\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python final_bowtie_shell.py prt_out_filenames.txt 3 batch_2_df batch_2_final.sam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. ``pstacks``\n",
    "\n",
    "``pstacks`` [documentation](http://catchenlab.life.illinois.edu/stacks/comp/pstacks.php) highlights:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pstacks -t file_type -f file_path [-o path] [-i id] [-m min_cov] [-p num_threads] [-h]\n",
    "<br>t — input file Type. Supported types: bowtie, sam, or bam.\n",
    "<br>f — input file path.\n",
    "<br>o — output path to write results.\n",
    "<br>i — SQL ID to insert into the output to identify this sample.\n",
    "<br>m — minimum depth of coverage to report a stack (default 1).\n",
    "<br>p — enable parallel execution with num_threads threads.\n",
    "<br>h — display this help messsage.\n",
    "<br>--pct_aln [num] — require read alignments to use at least this percentage of the read (default 85%).\n",
    "<br>--keep_sec_alns — keep secondary alignments (default: false, only keep primary alignments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/Volumes/Time Machine Backups/Cod-Time-Series-Data/Bowtie/bowtie-1.1.2'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/Time Machine Backups/Cod-Time-Series-Data/scripts\n"
     ]
    }
   ],
   "source": [
    "cd ../../scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min depth of coverage to report a stack: 3\n",
      "Model type: SNP\n",
      "Alpha significance level for model: 0.05\n",
      "Error opening input file '../bowtie-1.1.2/batch_2_ReferenceGenome.'\n",
      "Parsing ../bowtie-1.1.2/batch_2_ReferenceGenome.\n",
      "Loading aligned sequences...done\n",
      "Error: Unable to load data from '../bowtie-1.1.2/batch_2_ReferenceGenome.'.\n",
      "Finished running pstacks_shell.txt script.\n"
     ]
    }
   ],
   "source": [
    "!python pypipe_pstacks.py 3 bowtie ../bowtie-1.1.2/batch_2_ReferenceGenome. ../bowtie-1.1.2 2 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. ``sstacks``\n",
    "\n",
    "``sstacks`` [documentation](http://catchenlab.life.illinois.edu/stacks/comp/sstacks.php) highlights:\n",
    "\n",
    "<br>sstacks -b batch_id -c catalog_file -s sample_file [-s sample_file_2 ...] [-o path] [-p num_threads] [-g] [-x] [-v] [-h]\n",
    "<br>p — enable parallel execution with num_threads threads.\n",
    "<br>b — MySQL ID of this batch.\n",
    "<br>c — TSV file from which to load the catalog loci.\n",
    "<br>s — TSV file from which to load sample loci.\n",
    "<br>o — output path to write results.\n",
    "<br>g — base matching on genomic location, not sequence identity.\n",
    "<br>x — don’t verify haplotype of matching locus.\n",
    "<br>v — print program version.\n",
    "<br>h — display this help messsage.\n",
    "\n",
    "Running custom python [script for ``sstacks``](https://github.com/nclowell/FISH546/blob/master/Cod-Time-Series-Project/Scripts/pypipe_sstacks.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!python pypipe_sstacks.py new_filenames_shell.txt 2 ustacks_out/batch_1 ustacks_out 10 -o sstacks_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. ``populations``\n",
    "\n",
    "Documentation [here](http://catchenlab.life.illinois.edu/stacks/comp/populations.php).\n",
    "\n",
    "Example code:\n",
    "```\n",
    "!populations -b 2 -P ustacks_out -M popmap1.txt -t 10 -r 0.50 -p 2 -m 5 --genepop\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Additional filtering with Marine's scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 13. Statistical tests in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
